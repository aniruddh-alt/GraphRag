{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\aniru\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\aniru\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\aniru\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\aniru\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\aniru\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\aniru\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet langchain langchain-community langchain-ollama langchain-experimental neo4j pandas matplotlib tiktoken networkx py2neo yfiles_jupyter_graphs python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import os\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = os.getenv(\"NEO4J_URI\")\n",
    "user = os.getenv(\"NEO4J_USERNAME\")\n",
    "password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=url,\n",
    "    password=password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"dummytext.txt\")\n",
    "doc = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents=doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowGraph():\n",
    "    driver = GraphDatabase.driver(url, auth=(user, password))\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph = session.run(\"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t\").graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    return widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "llm = OllamaFunctions(model=\"llama3.1\", temperature=0, format=\"json\")\n",
    "\n",
    "llm_graph_transformer = LLMGraphTransformer(\n",
    "    llm=llm\n",
    ")\n",
    "graph_documents = llm_graph_transformer.convert_to_graph_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fixing the types of the nodes and relationships (handling null values)\n",
    "for g in graph_documents:\n",
    "    for reln in g.relationships:\n",
    "        if reln.target.type == '':\n",
    "            reln.target.type = 'MENTIONS'\n",
    "            print(reln)\n",
    "    for node in g.nodes:\n",
    "        if node.type == '':\n",
    "            node.type = 'ENTITY'\n",
    "            print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphDocument(nodes=[Node(id='Giovanni Caruso', type='Person', properties={}), Node(id='Maria', type='Person', properties={}), Node(id='Antonio Caruso', type='Person', properties={})], relationships=[Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Maria', type='Person', properties={}), type='SPOUSE', properties={}), Relationship(source=Node(id='Giovanni Caruso', type='Person', properties={}), target=Node(id='Antonio Caruso', type='Person', properties={}), type='PARENT', properties={})], source=Document(metadata={'source': 'dummytext.txt', 'id': 'f02d79f401c2ab5918868e8e9414ff13'}, page_content=\"Giovanni Caruso and Maria: The Founding Generation\\n\\nGiovanni Caruso, Amico's great-grandfather, was a man of the earth. His calloused hands spoke of years spent cultivating the fertile soils of Santa Caterina, producing olives and grapes that were the pride of the region. Giovanni was not just a farmer but an alchemist of flavors, blending the fruits of his labor into exquisite oils and wines. His wife, Maria, was the soul of the kitchen. A masterful cook, Maria's dishes were a symphony of hearty stews and delicate pastries, passed down from her ancestors and refined with her own touch. The couple's home was a haven of culinary experimentation and love, where their children were introduced to the secrets of the Sicilian kitchen.\\n\\nAntonio Caruso: The Storyteller and Innovator\"))"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_documents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents,\n",
    "                          baseEntityLabel=True,\n",
    "                          include_source=True\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e484ee6c074d169c19b5485785c307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ShowGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    embeddings,\n",
    "    search_type=\"hybrid\",\n",
    "    node_label=\"Document\",\n",
    "    text_node_properties=[\"text\"],\n",
    "    embedding_node_property=\"embedding\"\n",
    ")\n",
    "vector_retriever = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: List[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, organization, or business entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting organization and person entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "entity_chain = llm.with_structured_output(Entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_entities(result):\n",
    "    print(result)\n",
    "    raw_content = result['raw'].content\n",
    "    # Parse the JSON content\n",
    "    parsed_content = json.loads(raw_content)\n",
    "    # Extract the names list\n",
    "    names_list = []\n",
    "    if 'parameters' in parsed_content and 'names' in parsed_content['parameters']:\n",
    "        names = parsed_content['parameters']['names']\n",
    "        if isinstance(names, str):\n",
    "            names_list = json.loads(names)\n",
    "        elif isinstance(names, list):\n",
    "            names_list = names\n",
    "    return names_list\n",
    "\n",
    "entity_chain = prompt | llm.with_structured_output(Entities)\n",
    "result = entity_chain.invoke({\"question\": \"who is Nana Lucia?\"}).names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "        uri = os.environ[\"NEO4J_URI\"],\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
    "                os.environ[\"NEO4J_PASSWORD\"]))\n",
    "def create_fulltext_index(tx):\n",
    "    query = '''\n",
    "    CREATE FULLTEXT INDEX `fulltext_entity_id` \n",
    "    FOR (n:__Entity__) \n",
    "    ON EACH [n.id];\n",
    "    '''\n",
    "    tx.run(query)\n",
    "\n",
    "# Function to execute the query\n",
    "def create_index():\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(create_fulltext_index)\n",
    "        print(\"Fulltext index created successfully.\")\n",
    "\n",
    "# Call the function to create the index\n",
    "try:\n",
    "    create_index()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Close the driver connection\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    if not words:\n",
    "        return \"\"\n",
    "    full_text_query = \" AND \".join([f\"{word}~2\" for word in words])\n",
    "    print(f\"Generated Query: {full_text_query}\")\n",
    "    return full_text_query.strip()\n",
    "\n",
    "def graph_retriever(question: str) -> str:\n",
    "    entities = entity_chain.invoke({\"question\": question}).names\n",
    "    print(entities)\n",
    "    final_results = []\n",
    "\n",
    "    for entity in entities:\n",
    "        query = \"\"\"\n",
    "        CALL db.index.fulltext.queryNodes(\"fulltext_entity_id\", $query) YIELD node, score\n",
    "        CALL (node, score) {\n",
    "            WITH node\n",
    "            MATCH (node)-[r:!MENTIONS]->(neighbour)\n",
    "            RETURN node.id + ' - ' + type(r) + ' -> ' + neighbour.id AS output\n",
    "            UNION ALL\n",
    "            WITH node\n",
    "            MATCH (node)<-[r:!MENTIONS]-(neighbour)\n",
    "            RETURN neighbour.id + ' <- ' + type(r) + ' - ' + node.id AS output\n",
    "        }\n",
    "        RETURN output LIMIT 50;\n",
    "        \"\"\"\n",
    "        response = graph.query(query, {\"query\": (entity)})\n",
    "        final_results.extend(record['output'] for record in response)\n",
    "\n",
    "    return \"\\n\".join(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nonna Lucia']\n",
      "Nonna Lucia - MOTHER_OF -> Amico\n",
      "Nonna Lucia - GRANDMOTHER_OF -> Antonio\n",
      "Nonna Lucia - CUSTODIAN_OF -> family's recipes\n",
      "Nonna Lucia - TEACHER_OF -> Amico\n",
      "Nonna Lucia - INFLUENCED_BY -> family's love and wisdom\n",
      "Nonna Lucia - TEACHES_ABOUT -> life, love, community\n",
      "Nonna Lucia - SISTER -> Antonio\n",
      "Amico <- GRANDMOTHER - Nonna Lucia\n",
      "Lucia Caruso - OWNED_BY -> Bella Vita\n",
      "Lucia Caruso - INHERITED_TALENT -> her grandmother\n",
      "Lucia Caruso - COMMITTED_TO_SUSTAINABILITY -> sustainability\n",
      "Lucia Caruso - FOCUSED_ON -> sustainable cooking practices\n",
      "Lucia Caruso - FROM -> Sicily\n",
      "Bella Vita <- OWNS - Lucia Caruso\n",
      "Bella Vita - Los Angeles <- OWNED_BY - Lucia Caruso\n",
      "Caruso Family <- MEMBER - Lucia Caruso\n"
     ]
    }
   ],
   "source": [
    "print(graph_retriever(\"Who is Nonna Lucia?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_retriever(question: str):\n",
    "    graph_data = graph_retriever(question)\n",
    "    print(graph_data)\n",
    "    vector_data = [el.page_content for el in vector_retriever.invoke(question)]\n",
    "    final_data = f\"\"\"Graph data:\n",
    "{graph_data}\n",
    "vector data:\n",
    "{\"#Document \". join(vector_data)}\n",
    "    \"\"\"\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" \n",
    "    Answer the question based on only the following context provided:\n",
    "    {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    Use natural language to answer the question.\n",
    "    Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = (\n",
    "        {\n",
    "            \"context\": full_retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Attention is All You Need']\n",
      "Food for All - TARGETS_GROUP -> homeless and low-income families\n",
      "Food for All - INCLUDED_ACTIVITY -> food drives\n",
      "Carusos <- LAUNCHED_INITIATIVE - Food for All\n",
      "Food For All - SET_UP -> Community Kitchens\n",
      "Carusos <- LAUNCHED - Food For All\n",
      "self-attention - USED_IN -> Transformer\n",
      "Jakob <- PROPOSED - self-attention\n",
      "Transformer <- IS_FIRST_MODEL - self-attention\n",
      "models such as [17, 18] and [9] <- COMPARED_WITH - self-attention\n",
      "attention mechanisms - ALLOWED -> modeling of dependencies without regard to their distance in the input or output sequences\n",
      "recurrent network <- USED_WITH - attention mechanisms\n",
      "Transformer <- USES_ATTENTION_MECHANISM - attention mechanism\n",
      "Self-attention - USED_IN -> reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations\n",
      "Transformer <- USES - Multi-Head Attention\n",
      "End-to-end memory networks <- BASED_ON - recurrent attention mechanism\n",
      "multi-head attention - IMPLEMENTED_IN -> decoder stack\n",
      "Noam <- PROPOSED - multi-head attention\n",
      "Noam <- PROPOSED - scaled dot-product attention\n",
      "self-attention sub-layer - MODIFIED_TO_PREVENT_POSITIONS_ATTENDING_SUBSEQUENT_POSITIONS -> decoder stack\n",
      "Encoder <- USES_MULTI_HEAD_SELF_ATTENTION - multi-head self-attention mechanism\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The paper Attention Is All You Need covers various topics, including sequence transduction models, attention mechanisms, and a new simple network architecture called the Transformer. It discusses how traditional recurrent or convolutional neural networks can be replaced with attention-based models, which have shown to perform well in tasks such as reading comprehension, abstractive summarization, and language modeling.'"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input=\"What are the topics covered in the paper Attention is All You Need?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
